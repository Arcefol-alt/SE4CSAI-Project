Loading dataset...
Dataset loaded with 676004 rows and 8 columns.
Preparing data for Form2Description...
Data preparation complete.
Splitting data into training and validation sets...
Training set size: 540803 rows, Validation set size: 135201 rows.
Loading tokenizer and model...
Tokenizer and model loaded.
Tokenizing data...
Tokenization complete.
Tokenizing data...
Tokenization complete.
Training starts here...
Epoch 1, Batch 10/2113, Batch Loss: 5.4766
Epoch 1, Batch 20/2113, Batch Loss: 4.5057
Epoch 1, Batch 30/2113, Batch Loss: 4.3125
Epoch 1, Batch 40/2113, Batch Loss: 4.0652
Epoch 1, Batch 50/2113, Batch Loss: 4.0129
Epoch 1, Batch 60/2113, Batch Loss: 3.9838
Epoch 1, Batch 70/2113, Batch Loss: 3.8108
Epoch 1, Batch 80/2113, Batch Loss: 3.8638
Epoch 1, Batch 90/2113, Batch Loss: 3.7212
Epoch 1, Batch 100/2113, Batch Loss: 3.6154
Epoch 1, Batch 110/2113, Batch Loss: 3.6039
Epoch 1, Batch 120/2113, Batch Loss: 3.6237
Epoch 1, Batch 130/2113, Batch Loss: 3.3977
Epoch 1, Batch 140/2113, Batch Loss: 3.4069
Epoch 1, Batch 150/2113, Batch Loss: 3.4721
Epoch 1, Batch 160/2113, Batch Loss: 3.3321
Epoch 1, Batch 170/2113, Batch Loss: 3.4697
Epoch 1, Batch 180/2113, Batch Loss: 3.2631
Epoch 1, Batch 190/2113, Batch Loss: 3.3405
Epoch 1, Batch 200/2113, Batch Loss: 3.2242
Epoch 1, Batch 210/2113, Batch Loss: 3.3084
Epoch 1, Batch 220/2113, Batch Loss: 3.2563
Epoch 1, Batch 230/2113, Batch Loss: 3.2251
Epoch 1, Batch 240/2113, Batch Loss: 3.0903
Epoch 1, Batch 250/2113, Batch Loss: 3.2602
Epoch 1, Batch 260/2113, Batch Loss: 3.3155
Epoch 1, Batch 270/2113, Batch Loss: 3.1458
Epoch 1, Batch 280/2113, Batch Loss: 3.1550
Epoch 1, Batch 290/2113, Batch Loss: 3.2281
Epoch 1, Batch 300/2113, Batch Loss: 3.2382
Epoch 1, Batch 310/2113, Batch Loss: 3.2350
Epoch 1, Batch 320/2113, Batch Loss: 3.0864
Epoch 1, Batch 330/2113, Batch Loss: 3.1140
Epoch 1, Batch 340/2113, Batch Loss: 3.1006
Epoch 1, Batch 350/2113, Batch Loss: 3.2137
Epoch 1, Batch 360/2113, Batch Loss: 3.2034
Epoch 1, Batch 370/2113, Batch Loss: 3.0817
Epoch 1, Batch 380/2113, Batch Loss: 3.1540
Epoch 1, Batch 390/2113, Batch Loss: 3.0262
Epoch 1, Batch 400/2113, Batch Loss: 3.2095
Epoch 1, Batch 410/2113, Batch Loss: 2.9213
Epoch 1, Batch 420/2113, Batch Loss: 3.0921
Epoch 1, Batch 430/2113, Batch Loss: 3.1136
Epoch 1, Batch 440/2113, Batch Loss: 2.9996
Epoch 1, Batch 450/2113, Batch Loss: 3.1131
Epoch 1, Batch 460/2113, Batch Loss: 3.1631
Epoch 1, Batch 470/2113, Batch Loss: 3.0304
Epoch 1, Batch 480/2113, Batch Loss: 3.1351
Epoch 1, Batch 490/2113, Batch Loss: 3.0301
Epoch 1, Batch 500/2113, Batch Loss: 3.1776
Epoch 1, Batch 510/2113, Batch Loss: 3.1167
Epoch 1, Batch 520/2113, Batch Loss: 3.0389
Epoch 1, Batch 530/2113, Batch Loss: 3.0828
Epoch 1, Batch 540/2113, Batch Loss: 2.8622
Epoch 1, Batch 550/2113, Batch Loss: 3.0719
Epoch 1, Batch 560/2113, Batch Loss: 2.9316
Epoch 1, Batch 570/2113, Batch Loss: 3.0313
Epoch 1, Batch 580/2113, Batch Loss: 2.8407
Epoch 1, Batch 590/2113, Batch Loss: 2.8575
Epoch 1, Batch 600/2113, Batch Loss: 2.9440
Epoch 1, Batch 610/2113, Batch Loss: 2.8438
Epoch 1, Batch 620/2113, Batch Loss: 2.9436
Epoch 1, Batch 630/2113, Batch Loss: 2.8949
Epoch 1, Batch 640/2113, Batch Loss: 2.9974
Epoch 1, Batch 650/2113, Batch Loss: 2.9397
Epoch 1, Batch 660/2113, Batch Loss: 3.0904
Epoch 1, Batch 670/2113, Batch Loss: 3.0234
Epoch 1, Batch 680/2113, Batch Loss: 2.9398
Epoch 1, Batch 690/2113, Batch Loss: 2.8153
Epoch 1, Batch 700/2113, Batch Loss: 2.9925
Epoch 1, Batch 710/2113, Batch Loss: 3.0114
Epoch 1, Batch 720/2113, Batch Loss: 2.9371
Epoch 1, Batch 730/2113, Batch Loss: 2.9767
Epoch 1, Batch 740/2113, Batch Loss: 2.9887
Epoch 1, Batch 750/2113, Batch Loss: 2.9460
Epoch 1, Batch 760/2113, Batch Loss: 2.9836
Epoch 1, Batch 770/2113, Batch Loss: 2.8178
Epoch 1, Batch 780/2113, Batch Loss: 3.0231
Epoch 1, Batch 790/2113, Batch Loss: 2.9716
Epoch 1, Batch 800/2113, Batch Loss: 2.9722
Epoch 1, Batch 810/2113, Batch Loss: 2.7632
Epoch 1, Batch 820/2113, Batch Loss: 2.8980
Epoch 1, Batch 830/2113, Batch Loss: 2.7488
Epoch 1, Batch 840/2113, Batch Loss: 2.8406
Epoch 1, Batch 850/2113, Batch Loss: 2.8178
Epoch 1, Batch 860/2113, Batch Loss: 2.9524
Epoch 1, Batch 870/2113, Batch Loss: 2.8627
Epoch 1, Batch 880/2113, Batch Loss: 2.8759
Epoch 1, Batch 890/2113, Batch Loss: 2.8653
Epoch 1, Batch 900/2113, Batch Loss: 2.9069
Epoch 1, Batch 910/2113, Batch Loss: 2.8434
Epoch 1, Batch 920/2113, Batch Loss: 2.9561
Epoch 1, Batch 930/2113, Batch Loss: 2.9614
Epoch 1, Batch 940/2113, Batch Loss: 2.9137
Epoch 1, Batch 950/2113, Batch Loss: 2.8170
Epoch 1, Batch 960/2113, Batch Loss: 2.8552
Epoch 1, Batch 970/2113, Batch Loss: 2.8715
Epoch 1, Batch 980/2113, Batch Loss: 2.8505
Epoch 1, Batch 990/2113, Batch Loss: 2.8656
Epoch 1, Batch 1000/2113, Batch Loss: 2.8902
Epoch 1, Batch 1010/2113, Batch Loss: 2.7410
Epoch 1, Batch 1020/2113, Batch Loss: 2.8465
Epoch 1, Batch 1030/2113, Batch Loss: 2.8844
Epoch 1, Batch 1040/2113, Batch Loss: 2.8251
Epoch 1, Batch 1050/2113, Batch Loss: 2.8241
Epoch 1, Batch 1060/2113, Batch Loss: 2.9584
Epoch 1, Batch 1070/2113, Batch Loss: 2.8549
Epoch 1, Batch 1080/2113, Batch Loss: 2.8025
Epoch 1, Batch 1090/2113, Batch Loss: 2.7254
Epoch 1, Batch 1100/2113, Batch Loss: 3.0195
Epoch 1, Batch 1110/2113, Batch Loss: 2.8022
Epoch 1, Batch 1120/2113, Batch Loss: 2.8985
Epoch 1, Batch 1130/2113, Batch Loss: 2.7822
Epoch 1, Batch 1140/2113, Batch Loss: 2.8908
Epoch 1, Batch 1150/2113, Batch Loss: 2.6694
Epoch 1, Batch 1160/2113, Batch Loss: 2.7229
Epoch 1, Batch 1170/2113, Batch Loss: 2.8736
Epoch 1, Batch 1180/2113, Batch Loss: 2.7916
Epoch 1, Batch 1190/2113, Batch Loss: 2.8130
Epoch 1, Batch 1200/2113, Batch Loss: 2.8539
Epoch 1, Batch 1210/2113, Batch Loss: 2.7701
Epoch 1, Batch 1220/2113, Batch Loss: 2.7305
Epoch 1, Batch 1230/2113, Batch Loss: 2.7873
Epoch 1, Batch 1240/2113, Batch Loss: 2.8452
Epoch 1, Batch 1250/2113, Batch Loss: 2.9032
Epoch 1, Batch 1260/2113, Batch Loss: 2.8604
Epoch 1, Batch 1270/2113, Batch Loss: 2.7796
Epoch 1, Batch 1280/2113, Batch Loss: 2.7354
Epoch 1, Batch 1290/2113, Batch Loss: 2.7366
Epoch 1, Batch 1300/2113, Batch Loss: 2.8585
Epoch 1, Batch 1310/2113, Batch Loss: 2.7489
Epoch 1, Batch 1320/2113, Batch Loss: 2.7310
Epoch 1, Batch 1330/2113, Batch Loss: 2.7130
Epoch 1, Batch 1340/2113, Batch Loss: 2.8349
Epoch 1, Batch 1350/2113, Batch Loss: 2.7271
Epoch 1, Batch 1360/2113, Batch Loss: 2.7201
Epoch 1, Batch 1370/2113, Batch Loss: 2.7971
Epoch 1, Batch 1380/2113, Batch Loss: 2.7873
Epoch 1, Batch 1390/2113, Batch Loss: 2.7153
Epoch 1, Batch 1400/2113, Batch Loss: 2.7209
Epoch 1, Batch 1410/2113, Batch Loss: 2.7265
Epoch 1, Batch 1420/2113, Batch Loss: 2.8140
Epoch 1, Batch 1430/2113, Batch Loss: 2.7151
Epoch 1, Batch 1440/2113, Batch Loss: 2.7667
Epoch 1, Batch 1450/2113, Batch Loss: 2.7649
Epoch 1, Batch 1460/2113, Batch Loss: 2.7725
Epoch 1, Batch 1470/2113, Batch Loss: 2.8613
Epoch 1, Batch 1480/2113, Batch Loss: 2.6618
Epoch 1, Batch 1490/2113, Batch Loss: 2.6974
Epoch 1, Batch 1500/2113, Batch Loss: 2.8619
Epoch 1, Batch 1510/2113, Batch Loss: 2.8146
Epoch 1, Batch 1520/2113, Batch Loss: 2.8481
Epoch 1, Batch 1530/2113, Batch Loss: 2.7102
Epoch 1, Batch 1540/2113, Batch Loss: 2.7212
Epoch 1, Batch 1550/2113, Batch Loss: 2.8063
Epoch 1, Batch 1560/2113, Batch Loss: 2.7423
Epoch 1, Batch 1570/2113, Batch Loss: 2.8143
Epoch 1, Batch 1580/2113, Batch Loss: 2.7030
Epoch 1, Batch 1590/2113, Batch Loss: 2.7773
Epoch 1, Batch 1600/2113, Batch Loss: 2.6724
Epoch 1, Batch 1610/2113, Batch Loss: 2.7464
Epoch 1, Batch 1620/2113, Batch Loss: 2.7031
Epoch 1, Batch 1630/2113, Batch Loss: 2.7027
Epoch 1, Batch 1640/2113, Batch Loss: 2.6373
Epoch 1, Batch 1650/2113, Batch Loss: 2.7497
Epoch 1, Batch 1660/2113, Batch Loss: 2.7071
Epoch 1, Batch 1670/2113, Batch Loss: 2.6990
Epoch 1, Batch 1680/2113, Batch Loss: 2.7245
Epoch 1, Batch 1690/2113, Batch Loss: 2.6325
Epoch 1, Batch 1700/2113, Batch Loss: 2.6434
Epoch 1, Batch 1710/2113, Batch Loss: 2.7903
Epoch 1, Batch 1720/2113, Batch Loss: 2.6970
Epoch 1, Batch 1730/2113, Batch Loss: 2.7502
Epoch 1, Batch 1740/2113, Batch Loss: 2.6423
Epoch 1, Batch 1750/2113, Batch Loss: 2.7095
Epoch 1, Batch 1760/2113, Batch Loss: 2.7987
Epoch 1, Batch 1770/2113, Batch Loss: 2.6914
Epoch 1, Batch 1780/2113, Batch Loss: 2.6540
Epoch 1, Batch 1790/2113, Batch Loss: 2.6460
Epoch 1, Batch 1800/2113, Batch Loss: 2.7398
Epoch 1, Batch 1810/2113, Batch Loss: 2.8352
Epoch 1, Batch 1820/2113, Batch Loss: 2.6694
Epoch 1, Batch 1830/2113, Batch Loss: 2.6644
Epoch 1, Batch 1840/2113, Batch Loss: 2.6389
Epoch 1, Batch 1850/2113, Batch Loss: 2.6889
Epoch 1, Batch 1860/2113, Batch Loss: 2.8101
Epoch 1, Batch 1870/2113, Batch Loss: 2.6551
Epoch 1, Batch 1880/2113, Batch Loss: 2.6707
Epoch 1, Batch 1890/2113, Batch Loss: 2.7557
Epoch 1, Batch 1900/2113, Batch Loss: 2.6535
Epoch 1, Batch 1910/2113, Batch Loss: 2.7857
Epoch 1, Batch 1920/2113, Batch Loss: 2.6595
Epoch 1, Batch 1930/2113, Batch Loss: 2.5286
Epoch 1, Batch 1940/2113, Batch Loss: 2.7690
Epoch 1, Batch 1950/2113, Batch Loss: 2.7259
Epoch 1, Batch 1960/2113, Batch Loss: 2.6883
Epoch 1, Batch 1970/2113, Batch Loss: 2.6176
Epoch 1, Batch 1980/2113, Batch Loss: 2.6949
Epoch 1, Batch 1990/2113, Batch Loss: 2.5710
Epoch 1, Batch 2000/2113, Batch Loss: 2.7315
Epoch 1, Batch 2010/2113, Batch Loss: 2.7193
Epoch 1, Batch 2020/2113, Batch Loss: 2.7485
Epoch 1, Batch 2030/2113, Batch Loss: 2.7587
Epoch 1, Batch 2040/2113, Batch Loss: 2.5706
Epoch 1, Batch 2050/2113, Batch Loss: 2.6962
Epoch 1, Batch 2060/2113, Batch Loss: 2.6004
Epoch 1, Batch 2070/2113, Batch Loss: 2.6478
Epoch 1, Batch 2080/2113, Batch Loss: 2.6974
Epoch 1, Batch 2090/2113, Batch Loss: 2.6429
Epoch 1, Batch 2100/2113, Batch Loss: 2.7060
Epoch 1, Batch 2110/2113, Batch Loss: 2.5935
Epoch 1/2 - Train Loss: 2.9567 - Validation Loss: 2.4659 - Epoch Duration: 20187.21 seconds
Saving model to 'best_model'...
Model and tokenizer saved to 'best_model'.
Model improved at epoch 1 and saved as 'best_model'.
Epoch 2, Batch 10/2113, Batch Loss: 2.6068
Epoch 2, Batch 20/2113, Batch Loss: 2.7489
Epoch 2, Batch 30/2113, Batch Loss: 2.6770
Epoch 2, Batch 40/2113, Batch Loss: 2.6129
Epoch 2, Batch 50/2113, Batch Loss: 2.6756
Epoch 2, Batch 60/2113, Batch Loss: 2.5365
Epoch 2, Batch 70/2113, Batch Loss: 2.7397
Epoch 2, Batch 80/2113, Batch Loss: 2.6544
Epoch 2, Batch 90/2113, Batch Loss: 2.5487
Epoch 2, Batch 100/2113, Batch Loss: 2.6417
Epoch 2, Batch 110/2113, Batch Loss: 2.7302
Epoch 2, Batch 120/2113, Batch Loss: 2.6726
Epoch 2, Batch 130/2113, Batch Loss: 2.7284
